\section{Motivation}\label{motivation}
Access and retrieval mechanisms for archives and museums typically rely on a rich description of the collection. 
Most cultural heritage institutions employ professional experts to describe their collections by manually compiling metadata for each item. 
The subject matter of collection items can be very diverse, think for example of historic figures, animals, plants and buildings. Additionally, these aspects often carry a symbolic meaning.
To adequately describe items in large and diverse collections, the knowledge of experts from other domains is indispensable.
Cultural heritage institutions therefore seek to understand whether and how they can make use of external users, i.e. crowd users, to produce these annotations.

The work in this research aims at understanding which strategies and techniques lead to high-quality annotations by (crowds of) users that are external to the museum. For this, the detailed investigations are organised in terms of four connected challenges, that we will detail further in the next section. The first challenge in the project is to identify and model the niche of relevant experts and to motivate them to contribute to the annotation of collection items. 
Next, personalization mechanisms must make sure that the annotation task is adapted to the experts such that they are shown items that correspond to their expertise. 
The quality of the annotations and annotators is to be evaluated using algorithms considering trust. As a final challenge, all these aspects must be presented in an appropriate interface.

In order to perform the detailed investigations, and conduct the detailed studies and evaluations of our hypotheses, we develop a framework to support crowd annotation processes, called Accurator. It is employed in studies within the SEALINCMedia research project, for example in a use case with Rijksmuseum Amsterdam, as we will see in the example later. 