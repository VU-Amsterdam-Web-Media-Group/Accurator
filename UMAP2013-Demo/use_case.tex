\section{Research Challenges}
\label{use_case}

One of the challenges of nichesourcing is finding candidate annotators that will produce high quality annotations for collection items. 
%Besides topical knowledge, properties like availability, willingness to help and being able to share or transfer knowledge are also important. 
We believe that persons part of a topical community have an active interest in the topic and might be willing to help and share knowledge related to that topic. We call these topical communities niches and they manifest themselves, among others, on the Social Web. We will analyze social data and perform user studies using Accurator to understand what identifies a niche community, whether a person is part of such a community and which properties identify a good candidate to provide qualitative annotations. 

The challenge for recommender strategies in Accurator is twofold: keep the expertise needed to annotate the artwork in the range of the experts knowledge and yet diversify the suggestions to get high quality annotations for as many distinct artworks as possible. 
%To address these challenges we will investigate the use of content patterns in the Linked Data cloud. 
Our aim is to develop recommender strategies that use content patterns in the Linked Data cloud, resulting in a list of recommendations consisting of diverse artworks. 
% Using the alternative paths created by the patterns, items can be reached which reside in the long-tail. When experts are able to annotate these long-tail items, they will become more accessible in general. From a user perspective diversity is also important,
We hypothesize that encountering diverse artworks to annotate will help keep the expert motivated.

We address issues of determining trust in the users and their contributed annotations by modeling the user reputation and tracking their expertise across various topics over time. We intend to use Subjective logic to model the reputation of users and semantic similarity measures to track and update the users expertise. Since there is no gold standard for evaluating the annotations, we must rely on peer reviewing process and other mechanisms such as provenance of the annotation process.
% like tracking provenance of the annotation process such as usage of terms from vocabularies by the user, typing speed etc. We also investigate the different metrics which will help in identifying good behavior of the users. 

% The professional annotation of artworks is a complex process that requires familiarity with the used classification schemes and (art-)historical expert knowledge. Since both will mostly not be available in candidate users for nichesourcing projects,
Since external users are not familiar with classification schemes and (art-)historical expert knowldge, the annotation process must be broken down into facile tasks that can be solved with little effort and without this kind of expert knowledge (suggested in \cite{He2013}).
The interface for such a system has to present the task in a straightforward way while motivating the users to contribute their knowledge and time. We will investigate which design aspects and underlying mechanisms are responsible for the quality and quantity of tags added by users and how to visualize trust and personalization aspects.

