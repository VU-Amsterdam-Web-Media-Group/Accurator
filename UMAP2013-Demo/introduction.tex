\section{Introduction}\label{introduction}
Access and retrieval mechanisms for archives and museums rely on a rich description of the collection. 
Most cultural heritage institutions employ professional experts to describe their collections by manually compiling metadata for each item. 
For large and diverse collections the knowledge of experts from other domains is indispensable.
Cultural heritage institutions therefore seek to understand whether and how they can make use of external users to produce these annotations.

Our demo aims at understanding which strategies and techniques lead to high-quality annotations by (crowds of) external experts. 
The first challenge of the project is to identify the niche of relevant experts and to motivate them to contribute to the annotation of artworks. 
As a next step, the personalization mechanisms must make sure that the experts are shown items that correspond to their expertise. 
The quality of the annotations and annotators will be evaluated using trust algorithms. 
All these aspects must be presented in an appropriate interface.

To evaluate our hypotheses, we develop a framework designed to support crowd annotation processes, called Accurator. 